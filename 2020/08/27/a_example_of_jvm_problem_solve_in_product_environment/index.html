<!doctype html><html lang=en><head><title>记一次公司JVM堆溢出抽丝剥茧定位的过程 :: DongZhi.ME — A simple, retro blog for latest information technology!</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="背景 公司线上有个tomcat服务，里面合并部署了大概8个微服务，之所以没有像其他微服务那样单独部署，其目的是为了节约服务器资源，况且这8个服务是属于边缘服务，并发不高，就算宕机也不会影响核心业务。 因为"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://dongzhi.me/2020/08/27/a_example_of_jvm_problem_solve_in_product_environment/><link rel=stylesheet href=https://dongzhi.me/assets/style.css><link rel=apple-touch-icon sizes=180x180 href=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/dongzhi.me/favicon_io//apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/dongzhi.me/favicon_io//favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/dongzhi.me/favicon_io//favicon-16x16.png><link rel=manifest href=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/dongzhi.me/favicon_io//site.webmanifest><meta name=twitter:card content="summary"><meta name=twitter:creator content><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="记一次公司JVM堆溢出抽丝剥茧定位的过程 :: DongZhi.ME"><meta property="og:description" content="背景 公司线上有个tomcat服务，里面合并部署了大概8个微服务，之所以没有像其他微服务那样单独部署，其目的是为了节约服务器资源，况且这8个服务是属于边缘服务，并发不高，就算宕机也不会影响核心业务。 因为"><meta property="og:url" content="https://dongzhi.me/2020/08/27/a_example_of_jvm_problem_solve_in_product_environment/"><meta property="og:site_name" content="记一次公司JVM堆溢出抽丝剥茧定位的过程"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_01.png"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2020-08-27 20:09:50 +0800 +0800"><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/modules/plyr/3.6.2/plyr.css><link href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css rel=stylesheet></head><body><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>DongZhi.ME</div></a></div><div class=menu-trigger>menu</div></div><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/>Home</a></li><li><a href=/archives>Archives</a></li><li><a href=/tags>Tags</a></li><li><a href=/search>Search</a></li><li><a href=/about>About</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/>Home</a></li><li><a href=/archives>Archives</a></li><li><a href=/tags>Tags</a></li><li><a href=/search>Search</a></li><li><a href=/about>About</a></li></ul></nav></header><div class=content><div class=post><h1 class=post-title><a href=https://dongzhi.me/2020/08/27/a_example_of_jvm_problem_solve_in_product_environment/>记一次公司JVM堆溢出抽丝剥茧定位的过程</a></h1><div class=post-meta><span class=post-date>2020-08-27</span></div><span class=post-tags>#<a href=https://dongzhi.me/tags/jvm/>jvm</a>&nbsp;</span>
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_01.png class=post-cover alt=记一次公司JVM堆溢出抽丝剥茧定位的过程><div class=post-content><div><h1 id=背景>背景<a href=#背景 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>公司线上有个tomcat服务，里面合并部署了大概8个微服务，之所以没有像其他微服务那样单独部署，其目的是为了节约服务器资源，况且这8个服务是属于边缘服务，并发不高，就算宕机也不会影响核心业务。</p><p>因为并发不高，所以线上一共部署了2个tomcat进行负载均衡。</p><p>这个tomcat刚上生产线，运行挺平稳。大概过了大概 1 天后，运维同事反映2个tomcat 节点均挂了。无法接受新的请求了。CPU 飙升到 100%。</p><h1 id=排查过程一>排查过程一<a href=#排查过程一 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>接手这个问题后。首先大致看了下当时的 JVM 监控。CPU 的确居高不下:
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_01.png alt></p><p>FULL GC从大概这个小时的22分开始，就开始频繁的进行FULL GC，一分钟最高能进行10次FULL GC:
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_02.png alt></p><p>minor GC 每分钟竟然接近60次，相当于每秒钟都有minor GC。如图：
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_03.png alt></p><p>同时，从老年代的使用情况也反应了这一点:
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_04.png alt></p><p>接着，随机对线上应用分析了线程的 cpu 占用情况，用<code>top -H -p pid</code> 命令:
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_05.png alt></p><p>可以看到前面 4 条线程，都占用了大量的 CPU 资源。随即进行了 jstack，把线程栈信息拉下来，用前面 4 条线程的 ID 转换 16 进制后进行搜索。发现并没有找到相应的线程。所以判断为不是应用线程导致的。</p><h1 id=第一个结论>第一个结论<a href=#第一个结论 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>通过对当时JVM的的监控情况，可以发现：这个小时的22分之前，系统一直保持着一个比较稳定的运行状态，堆的使用率不高，但是，在22分钟时年轻代大量的minor gc后，老年代在几分钟之内被快速的填满，导致了FULL GC。同时FULL GC不停的发生，导致了大量的STW，CPU被FULL GC线程占据，出现CPU飙高，应用线程由于STW再加上CPU过高，大量线程被阻塞。同时新的请求又不停的进来，最终tomcat的线程池被占满，再也无法响应新的请求了。这个雪球终于还是滚大了。</p><p>分析完了案发现场。要解决的问题变成了：<strong>是什么原因导致老年代被快速的填满？</strong>
拉了下当时的JVM 参数:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span>-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms2048m -Xmx4096m -Xmn2048m -Xss512k -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m -XX:+DisableExx plicitGC -XX:MaxTenuringThreshold=5 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection
<span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span>-XX:+PrintGCDetails -Xloggc:/data/logs/gc.log
</code></pre></div><p>总共4个G的堆，年轻代单独给了2个G，按照比率算，JVM 内存各个区的分配情况如下：
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_06.png alt></p><p>所以开始怀疑是 JVM 参数设置的有问题导致的老年代被快速的占满。</p><p>但是其实这参数已经是之前优化后的结果了，eden 区设置的挺大，大部分我们的方法产生的对象都是朝生夕死的对象，应该大部分都在年轻代会清理了。存活的对象才会进入survivor区。到达年龄或者触发了进入老年代的条件后才会进入老年代。基本上老年代里的对象大部分应该是一直存活的对象。比如static修饰的对象啊，一直被引用的 缓存啊，spring 容器中的 bean 等等。</p><p>我看了下垃圾回收进入老年代的触发条件后，发现这个场景应该是属于大对象直接进老年代的这种，也就是说年轻代进行minor GC后，存活的对象足够大，不足以在survivor区域放下了，就直接进入老年代了。</p><p>但是一次minor GC应该超过90%的对象都是无引用对象，只有少部分的对象才是存活的。而且这些个服务的并发一直不高，为什么一次minor GC后有那么大量的数据会存活呢。</p><p>随即看了下当时的<code>jmap -histo</code>命令产生的文件:</p><p><img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_07.png alt></p><p>发现String这个这个对象的示例竟然有9000多w个，占用堆超过2G。这肯定有问题。但是tomcat里有8个应用，不可能通过分析代码来定位到。还是要从JVM入手来反推。</p><h1 id=第二次结论>第二次结论<a href=#第二次结论 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>程序并发不高，但是在几分钟之内，在eden区产生了大量的对象，并且这些对象无法被minor GC回收 ，由于太大，触发了大对象直接进老年代机制，老年代会迅速填满，导致FULL GC，和后面CPU的飙升，从而导致 tomcat 的宕机。</p><p>基本判断是，JVM参数应该没有问题，很可能问题出在应用本身不断产生无法被回收的对象上面。但是我暂时定位不到具体的代码位置。</p><h1 id=排查过程二>排查过程二<a href=#排查过程二 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>第二天，又看了下当时的 JVM 监控，发现有这么一个监控数据当时漏看了:
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_08.png alt></p><p>这是FULL GC之后老年代的使用率。可以看到,FULL GC之后老年代依然占据80%多的空间，FULL GC就根本清理不掉老年代的对象。这说明，老年代里的这些对象都是被程序引用着的，所以清理不掉。但是平稳的时候，老年代一直维持着大概300M的堆，从这个小时的 22 分开始，之后就狂飙到接近2G，这肯定不正常。更加印证了我前面一个观点：<strong>这是因为应用程序产生的无法回收的对象导致的</strong>。</p><p>但是，当时我并没有dump下来jvm的堆，所以只能等再次重现问题。</p><p>终于，在晚上 9 点多，这个问题又重现了，熟悉的配方，熟悉的味道。</p><p>直接<code>jmap -dump</code>，经过漫长的等待，产生了4.2G的一个堆快照文件dump.hprof，经过压缩，得到一个466M的tar.gz文件</p><p>然后download 到本地，解压。</p><p>运行堆分析工具<code>JProfile</code>，装载这个dump.hprof 文件。然后查看堆当时的所有类占比大小的信息：</p><p><img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_09.png alt></p><p>发现导致堆溢出，就是这个String对象，和之前Jmap 得出的结果一样，超过了2个G，并且无法被回收。随即看大对象视图，发现这些个String对象都是被<strong>java.util.ArrayList</strong>引用着的，也就是有一个ArrayList里，引用了超过2G的对象：
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_10.png alt></p><p>然后查看引用的关系图，往上溯源，源头终于显形：
<img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_11.png alt></p><p>这个ArrayList是被一个线程栈引用着，而这个线程栈信息里面，可以直接定位到相应的服务和相应的类。具体服务是Media这个微服务。</p><p>看来已经要逼近真相了！</p><h1 id=第三次结论>第三次结论<a href=#第三次结论 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>本次大量频繁的FULL GC是因为应用程序产生了大量无法被回收的数据，最终进入老年代，最终把老年代撑满了导致的。具体的定位通过JVM的dump文件已经分析出，指向了Media这个服务的 ImageCombineUtils.getComputedLines 这个方法，是什么会产生尚不知道，需要具体分析代码。</p><h1 id=最后>最后<a href=#最后 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>得知了具体的代码位置，直接进去看。经过小伙伴提醒，发现这个代码有一个问题:</p><p>这段代码为一个拆词方法，具体代码就不贴了，里面有一个循环，每一次循环会往一个ArrayList里加一个String对象，在循环的某一个阶段，会重置循环计数器 i，在普通的参数下并没有问题。但是某些特定的条件下。就会不停的重置循环计数器 i，导致一个死循环。</p><p>以下是模拟出来的结果，可以看到，才运行了一会，这个ArrayList就产生了322w个对象，且大部分Stirng对象都是空值。</p><p><img src=https://cdn.jsdelivr.net/gh/bugfix123/CDN/9527/post/images/2020/jvm_problem_12.png alt></p><p>至此，水落石出。</p><h1 id=最终结论>最终结论<a href=#最终结论 class=hanchor arialabel=Anchor>&#8983;</a></h1><p>因为Media这个微服务的程序在某一些特殊场景下的一段程序导致了死循环，产生了一个超大的ArrayList。导致了年轻代的快速被填满，然后触发了大对象直接进老年代的机制，直接往老年代里面放。老年代被放满之后。触发FULL GC。但是这些ArrayList被<code>GC ROOT</code>根引用着，无法回收。导致回收不掉。老年代依旧满的，随机马上又触发FULL GC。同时因为老年代无法被回收，导致minor GC也没法清理，不停的进行minor GC。大量GC导致STW和CPU飙升，导致应用线程卡顿，阻塞，直至最后整个服务无法接受请求。</p><blockquote><p><strong>备注</strong>:本文转载自https://www.v2ex.com/t/701513</p></blockquote></div></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button next"><a href=https://dongzhi.me/2020/08/21/kexueshangwang/><span class=button__text>v2ray客户端配置简易说明</span>
<span class=button__icon>→</span></a></span></div></div><h3 style=margin-inline-start:1em;margin-bottom:auto>评论</h3><aside id=comments><div id=hyvor-talk-view></div><script type=text/javascript>var HYVOR_TALK_WEBSITE=1505;var HYVOR_TALK_CONFIG={url:false,id:false};</script><script async type=text/javascript src=https://talk.hyvor.com/web-api/embed></script></aside></div></div><footer class=footer><div class=footer__inner><div class=copyright><span>© 2020 Powered by <a href=http://gohugo.io>Hugo</a></span>
<span style=margin-right:10px>:: Theme made by <a href=https://twitter.com/panr>panr</a></span>
<span id=busuanzi_container_site_uv>:: 您是本站第<span id=busuanzi_value_site_uv></span>位访客</span></div></div></footer><script src=https://dongzhi.me/assets/main.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/gh/bugfix123/CDN@master/modules/plyr/3.6.2/plyr.polyfilled.min.js></script><script>const players=Plyr.setup('.js-player',{iconUrl:'/modules/plyr/3.6.2/plyr.svg'});</script></div></body></html>